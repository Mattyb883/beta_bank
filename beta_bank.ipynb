{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "175bb62e-4f1e-4dbd-a112-3ed71d7d0bd0",
   "metadata": {},
   "source": [
    "# Predicting Customer Churn for Beta Bank\n",
    "\n",
    "## Project Overview\n",
    "Beta Bank is facing a challenge with customer churn. The bank has realized that retaining existing customers is more cost-effective than acquiring new ones. This project aims to predict whether a customer will leave the bank using historical customer data. By building a predictive model, Beta Bank can take proactive measures to retain valuable customers.\n",
    "\n",
    "## Objectives\n",
    "1. Prepare and preprocess the data for analysis and modeling.\n",
    "2. Investigate the balance of classes and train a baseline model.\n",
    "3. Use techniques to handle class imbalance and improve model performance.\n",
    "4. Experiment with multiple models and parameters to achieve the best results.\n",
    "5. Evaluate the final model on the test set and ensure the F1 score is **≥ 0.59**.\n",
    "6. Compare the F1 score with the AUC-ROC metric.\n",
    "\n",
    "## Dataset Description\n",
    "The dataset includes the following features:\n",
    "\n",
    "### Features:\n",
    "- `RowNumber` — Data string index\n",
    "- `CustomerId` — Unique customer identifier\n",
    "- `Surname` — Customer's surname\n",
    "- `CreditScore` — Customer's credit score\n",
    "- `Geography` — Customer's country of residence\n",
    "- `Gender` — Customer's gender\n",
    "- `Age` — Customer's age\n",
    "- `Tenure` — Period of account maturity (years)\n",
    "- `Balance` — Customer's account balance\n",
    "- `NumOfProducts` — Number of banking products used by the customer\n",
    "- `HasCrCard` — Whether the customer has a credit card (binary)\n",
    "- `IsActiveMember` — Customer's activity status (binary)\n",
    "- `EstimatedSalary` — Estimated salary of the customer\n",
    "\n",
    "### Target:\n",
    "- `Exited` — Whether the customer left the bank (binary: 0 = stayed, 1 = left)\n",
    "\n",
    "## Evaluation Metrics\n",
    "- F1 Score (Minimum required: **≥ 0.59**)\n",
    "- AUC-ROC Score (To compare with F1)\n",
    "\n",
    "## Methodology\n",
    "The project will be conducted in the following stages:\n",
    "1. Data preparation and preprocessing.\n",
    "2. Class balance investigation and baseline modeling.\n",
    "3. Improving model performance with imbalance handling.\n",
    "4. Final testing and evaluation.\n",
    "\n",
    "## Tools and Libraries\n",
    "The project utilized the following libraries:\n",
    "- **Pandas**: For data manipulation and analysis.\n",
    "- **NumPy**: For numerical operations.\n",
    "- **Matplotlib**: For data visualization.\n",
    "- **Sklearn**:\n",
    "  - `LogisticRegression`, `RandomForestClassifier`, `GradientBoostingClassifier`: To build and evaluate models.\n",
    "  - `train_test_split`, `f1_score`, `roc_auc_score`: For model validation.\n",
    "- **XGBoost**:\n",
    "  - `XGBClassifier`: For building the final predictive model.\n",
    "\n",
    "---\n",
    "\n",
    "Let's begin by preparing and examining the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5dbbc71-45e7-4ca0-b34d-fbee09fb0ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
      "0          1    15634602  Hargrave          619    France  Female   42   \n",
      "1          2    15647311      Hill          608     Spain  Female   41   \n",
      "2          3    15619304      Onio          502    France  Female   42   \n",
      "3          4    15701354      Boni          699    France  Female   39   \n",
      "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
      "\n",
      "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
      "0     2.0       0.00              1          1               1   \n",
      "1     1.0   83807.86              1          0               1   \n",
      "2     8.0  159660.80              3          1               0   \n",
      "3     1.0       0.00              2          0               0   \n",
      "4     2.0  125510.82              1          1               1   \n",
      "\n",
      "   EstimatedSalary  Exited  \n",
      "0        101348.88       1  \n",
      "1        112542.58       0  \n",
      "2        113931.57       1  \n",
      "3         93826.63       0  \n",
      "4         79084.10       0  \n",
      "(10000, 14)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           9091 non-null   float64\n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = '/Users/mattbaglietto/beta_bank/churn.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(data.head())\n",
    "\n",
    "# Display the shape of the dataset\n",
    "print(data.shape)\n",
    "\n",
    "# Check for missing values and data types\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44a6b890-521d-4b40-b770-ba77dbbf43d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    9091.000000\n",
      "mean        4.997690\n",
      "std         2.894723\n",
      "min         0.000000\n",
      "25%         2.000000\n",
      "50%         5.000000\n",
      "75%         7.000000\n",
      "max        10.000000\n",
      "Name: Tenure, dtype: float64\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Investigate the distribution of the 'Tenure' column\n",
    "print(data['Tenure'].describe())\n",
    "\n",
    "# Fill missing values in the 'Tenure' column with the median\n",
    "data['Tenure'] = data['Tenure'].fillna(data['Tenure'].median())\n",
    "\n",
    "# Verify that there are no missing values\n",
    "print(data['Tenure'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54033406-54ab-4caf-bb79-e50f4aee9303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
      "0          619    France  Female   42     2.0       0.00              1   \n",
      "1          608     Spain  Female   41     1.0   83807.86              1   \n",
      "2          502    France  Female   42     8.0  159660.80              3   \n",
      "3          699    France  Female   39     1.0       0.00              2   \n",
      "4          850     Spain  Female   43     2.0  125510.82              1   \n",
      "\n",
      "   HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
      "0          1               1        101348.88       1  \n",
      "1          0               1        112542.58       0  \n",
      "2          1               0        113931.57       1  \n",
      "3          0               0         93826.63       0  \n",
      "4          1               1         79084.10       0  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   CreditScore      10000 non-null  int64  \n",
      " 1   Geography        10000 non-null  object \n",
      " 2   Gender           10000 non-null  object \n",
      " 3   Age              10000 non-null  int64  \n",
      " 4   Tenure           10000 non-null  float64\n",
      " 5   Balance          10000 non-null  float64\n",
      " 6   NumOfProducts    10000 non-null  int64  \n",
      " 7   HasCrCard        10000 non-null  int64  \n",
      " 8   IsActiveMember   10000 non-null  int64  \n",
      " 9   EstimatedSalary  10000 non-null  float64\n",
      " 10  Exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(6), object(2)\n",
      "memory usage: 859.5+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Drop irrelevant columns\n",
    "data = data.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1)\n",
    "\n",
    "# Verify the updated structure of the dataset\n",
    "print(data.head())\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68b1fcfe-a554-49f9-8d61-9b77edf1c167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CreditScore  Gender  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
      "0          619       0   42     2.0       0.00              1          1   \n",
      "1          608       0   41     1.0   83807.86              1          0   \n",
      "2          502       0   42     8.0  159660.80              3          1   \n",
      "3          699       0   39     1.0       0.00              2          0   \n",
      "4          850       0   43     2.0  125510.82              1          1   \n",
      "\n",
      "   IsActiveMember  EstimatedSalary  Exited  Geography_Germany  Geography_Spain  \n",
      "0               1        101348.88       1              False            False  \n",
      "1               1        112542.58       0              False             True  \n",
      "2               0        113931.57       1              False            False  \n",
      "3               0         93826.63       0              False            False  \n",
      "4               1         79084.10       0              False             True  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 12 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   CreditScore        10000 non-null  int64  \n",
      " 1   Gender             10000 non-null  int64  \n",
      " 2   Age                10000 non-null  int64  \n",
      " 3   Tenure             10000 non-null  float64\n",
      " 4   Balance            10000 non-null  float64\n",
      " 5   NumOfProducts      10000 non-null  int64  \n",
      " 6   HasCrCard          10000 non-null  int64  \n",
      " 7   IsActiveMember     10000 non-null  int64  \n",
      " 8   EstimatedSalary    10000 non-null  float64\n",
      " 9   Exited             10000 non-null  int64  \n",
      " 10  Geography_Germany  10000 non-null  bool   \n",
      " 11  Geography_Spain    10000 non-null  bool   \n",
      "dtypes: bool(2), float64(3), int64(7)\n",
      "memory usage: 800.9 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Perform One-Hot Encoding for 'Geography'\n",
    "data = pd.get_dummies(data, columns=['Geography'], drop_first=True)\n",
    "\n",
    "# Convert 'Gender' to binary: Female -> 0, Male -> 1\n",
    "data['Gender'] = data['Gender'].apply(lambda x: 1 if x == 'Male' else 0)\n",
    "\n",
    "# Verify the updated dataset\n",
    "print(data.head())\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9590ebc1-bce2-4caa-a240-5d89f18ad051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (6000, 11) (6000,)\n",
      "Validation set shape: (2000, 11) (2000,)\n",
      "Test set shape: (2000, 11) (2000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separate the target from the features\n",
    "target = data['Exited']\n",
    "features = data.drop(['Exited'], axis=1)\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "features_train, features_temp, target_train, target_temp = train_test_split(\n",
    "    features, target, test_size=0.4, random_state=12345\n",
    ")\n",
    "\n",
    "features_valid, features_test, target_valid, target_test = train_test_split(\n",
    "    features_temp, target_temp, test_size=0.5, random_state=12345\n",
    ")\n",
    "\n",
    "# Print the shapes of the resulting datasets\n",
    "print(\"Training set shape:\", features_train.shape, target_train.shape)\n",
    "print(\"Validation set shape:\", features_valid.shape, target_valid.shape)\n",
    "print(\"Test set shape:\", features_test.shape, target_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9841eed3-c817-4342-9e1b-09d3af436816",
   "metadata": {},
   "source": [
    "## Data Preparation Summary\n",
    "\n",
    "1. **Data Loading**:\n",
    "   - The dataset was loaded from `/Users/mattbaglietto/beta_bank/churn.csv`.\n",
    "\n",
    "2. **Handling Missing Values**:\n",
    "   - The `Tenure` column had 909 missing values.\n",
    "   - Missing values were replaced with the median value (`5`).\n",
    "\n",
    "3. **Dropping Irrelevant Columns**:\n",
    "   - The columns `RowNumber`, `CustomerId`, and `Surname` were dropped as they were irrelevant to the prediction task.\n",
    "\n",
    "4. **Encoding Categorical Variables**:\n",
    "   - `Geography`: One-hot encoded with `Geography_Germany` and `Geography_Spain` columns (dropped `Geography_France` to avoid dummy variable trap).\n",
    "   - `Gender`: Converted to binary (`Female = 0`, `Male = 1`).\n",
    "\n",
    "5. **Dataset Splitting**:\n",
    "   - The dataset was split into:\n",
    "     - **Training Set**: 60% of the data (6,000 rows).\n",
    "     - **Validation Set**: 20% of the data (2,000 rows).\n",
    "     - **Test Set**: 20% of the data (2,000 rows).\n",
    "   - Random seed (`random_state=12345`) was used for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82e0da4e-db20-40f5-8287-0faf5c00ebe6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution in the training set:\n",
      "Exited\n",
      "0    0.800667\n",
      "1    0.199333\n",
      "Name: proportion, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Check the class distribution\n",
    "class_counts = target_train.value_counts(normalize=True)\n",
    "print(\"Class distribution in the training set:\")\n",
    "print(class_counts)\n",
    "\n",
    "# Visualize class balance\n",
    "class_counts.plot(kind='bar', color=['skyblue', 'orange'], alpha=0.7)\n",
    "plt.title(\"Class Distribution in Training Set\")\n",
    "plt.xlabel(\"Exited (0 = Stayed, 1 = Left)\")\n",
    "plt.ylabel(\"Proportion\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d1df77-1808-4223-a382-752060cc9613",
   "metadata": {},
   "source": [
    "## Class Balance Investigation\n",
    "\n",
    "### Findings:\n",
    "- The target variable `Exited` is highly imbalanced in the training set:\n",
    "  - **80.07%** of the customers stayed (class `0`).\n",
    "  - **19.93%** of the customers left (class `1`).\n",
    "\n",
    "### Visualization:\n",
    "A bar chart was created to visualize the class distribution, confirming the imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4063feab-94c3-452d-bf04-fab0cee60b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Model Performance:\n",
      "F1 Score: 0.08385744234800839\n",
      "AUC-ROC: 0.6727947180904797\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "# Train logistic regression model\n",
    "baseline_model = LogisticRegression(random_state=12345, solver='liblinear')\n",
    "baseline_model.fit(features_train, target_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "baseline_predictions = baseline_model.predict(features_valid)\n",
    "\n",
    "# Calculate F1 Score\n",
    "baseline_f1 = f1_score(target_valid, baseline_predictions)\n",
    "\n",
    "# Calculate AUC-ROC\n",
    "baseline_probabilities = baseline_model.predict_proba(features_valid)[:, 1]\n",
    "baseline_auc_roc = roc_auc_score(target_valid, baseline_probabilities)\n",
    "\n",
    "print(\"Baseline Model Performance:\")\n",
    "print(\"F1 Score:\", baseline_f1)\n",
    "print(\"AUC-ROC:\", baseline_auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8948209a-e3d0-4a59-8ed4-df1b20d44570",
   "metadata": {},
   "source": [
    "## Baseline Model Performance\n",
    "\n",
    "### Findings:\n",
    "- A logistic regression model was trained without addressing class imbalance.\n",
    "- The performance metrics on the validation set were as follows:\n",
    "  - **F1 Score**: 0.0839\n",
    "  - **AUC-ROC**: 0.6728\n",
    "\n",
    "### Observations:\n",
    "- The F1 score is very low due to the imbalance, as the model predicts the majority class most of the time.\n",
    "- The AUC-ROC indicates some ability to distinguish between classes, but the model requires significant improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "41efecb1-e974-44c7-bb53-0568b396d0cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Model Performance:\n",
      "F1 Score: 0.4921030756442228\n",
      "AUC-ROC: 0.7541223331861431\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression with Class Weighting\n",
    "weighted_model = LogisticRegression(random_state=12345, solver='liblinear', class_weight='balanced')\n",
    "weighted_model.fit(features_train, target_train)\n",
    "\n",
    "# Predictions on validation set\n",
    "weighted_predictions = weighted_model.predict(features_valid)\n",
    "\n",
    "# Calculate F1 Score\n",
    "weighted_f1 = f1_score(target_valid, weighted_predictions)\n",
    "\n",
    "# Calculate AUC-ROC\n",
    "weighted_probabilities = weighted_model.predict_proba(features_valid)[:, 1]\n",
    "weighted_auc_roc = roc_auc_score(target_valid, weighted_probabilities)\n",
    "\n",
    "print(\"Weighted Model Performance:\")\n",
    "print(\"F1 Score:\", weighted_f1)\n",
    "print(\"AUC-ROC:\", weighted_auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f4eefc-fc9a-4a99-8e49-9861b5cdf4c5",
   "metadata": {},
   "source": [
    "## Addressing Class Imbalance: Class Weighting\n",
    "\n",
    "### Findings:\n",
    "- A logistic regression model was trained with the `class_weight='balanced'` parameter to handle class imbalance.\n",
    "- Performance metrics on the validation set:\n",
    "  - **F1 Score**: 0.4921\n",
    "  - **AUC-ROC**: 0.7541\n",
    "\n",
    "### Observations:\n",
    "- The F1 score improved significantly compared to the baseline model (0.0839 → 0.4921).\n",
    "- AUC-ROC indicates a stronger ability to distinguish between classes, showing the effectiveness of class weighting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ddeb09a3-14d3-4eba-be92-1c6c1554ff2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsampled Model Performance:\n",
      "F1 Score: 0.4512489927477841\n",
      "AUC-ROC: 0.7202726244412319\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Upsample the minority class\n",
    "features_zeros = features_train[target_train == 0]\n",
    "features_ones = features_train[target_train == 1]\n",
    "target_zeros = target_train[target_train == 0]\n",
    "target_ones = target_train[target_train == 1]\n",
    "\n",
    "features_upsampled = pd.concat([features_zeros] + [features_ones] * 4)\n",
    "target_upsampled = pd.concat([target_zeros] + [target_ones] * 4)\n",
    "\n",
    "# Shuffle the upsampled dataset\n",
    "features_upsampled, target_upsampled = shuffle(features_upsampled, target_upsampled, random_state=12345)\n",
    "\n",
    "# Train Logistic Regression on upsampled data\n",
    "upsampled_model = LogisticRegression(random_state=12345, solver='liblinear')\n",
    "upsampled_model.fit(features_upsampled, target_upsampled)\n",
    "\n",
    "# Predictions on validation set\n",
    "upsampled_predictions = upsampled_model.predict(features_valid)\n",
    "\n",
    "# Calculate F1 Score\n",
    "upsampled_f1 = f1_score(target_valid, upsampled_predictions)\n",
    "\n",
    "# Calculate AUC-ROC\n",
    "upsampled_probabilities = upsampled_model.predict_proba(features_valid)[:, 1]\n",
    "upsampled_auc_roc = roc_auc_score(target_valid, upsampled_probabilities)\n",
    "\n",
    "print(\"Upsampled Model Performance:\")\n",
    "print(\"F1 Score:\", upsampled_f1)\n",
    "print(\"AUC-ROC:\", upsampled_auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0366e073-9637-4294-a94c-02f4a2dee178",
   "metadata": {},
   "source": [
    "## Addressing Class Imbalance: Upsampling\n",
    "\n",
    "### Findings:\n",
    "- The minority class (`Exited = 1`) was upsampled by duplicating its examples in the training set to achieve a balanced dataset.\n",
    "- Performance metrics on the validation set:\n",
    "  - **F1 Score**: 0.4512\n",
    "  - **AUC-ROC**: 0.7203\n",
    "\n",
    "### Observations:\n",
    "- Upsampling improved the F1 score compared to the baseline model (0.0839 → 0.4512).\n",
    "- The AUC-ROC indicates better performance compared to the baseline model but is slightly lower than the weighted logistic regression.\n",
    "- Class weighting appears to be a more effective method for addressing the imbalance in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4c71d9b5-f015-465e-b521-1731a2f73d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Model Performance:\n",
      "F1 Score: 0.5691573926868044\n",
      "AUC-ROC: 0.8550242258905509\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "# Train Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, max_depth=8, random_state=12345)\n",
    "rf_model.fit(features_train, target_train)\n",
    "\n",
    "# Make predictions on validation set\n",
    "rf_predictions = rf_model.predict(features_valid)\n",
    "\n",
    "# Calculate F1 Score\n",
    "rf_f1 = f1_score(target_valid, rf_predictions)\n",
    "\n",
    "# Calculate AUC-ROC\n",
    "rf_probabilities = rf_model.predict_proba(features_valid)[:, 1]\n",
    "rf_auc_roc = roc_auc_score(target_valid, rf_probabilities)\n",
    "\n",
    "print(\"Random Forest Model Performance:\")\n",
    "print(\"F1 Score:\", rf_f1)\n",
    "print(\"AUC-ROC:\", rf_auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828f4a4c-30df-4d41-ae28-cf8e5e502b30",
   "metadata": {},
   "source": [
    "## Random Forest Model Performance\n",
    "\n",
    "### Findings:\n",
    "- A Random Forest model was trained with the following parameters:\n",
    "  - `n_estimators=100`\n",
    "  - `max_depth=8`\n",
    "  - `random_state=12345`\n",
    "- Performance metrics on the validation set:\n",
    "  - **F1 Score**: 0.5692\n",
    "  - **AUC-ROC**: 0.8550\n",
    "\n",
    "### Observations:\n",
    "- The F1 score is the highest achieved so far, demonstrating the Random Forest's strength in handling the class imbalance.\n",
    "- AUC-ROC indicates a strong ability to distinguish between the two classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b0e275c8-313f-478f-8054-0fb02de625c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: n_estimators = 300 , max_depth = 12\n",
      "Best F1 Score: 0.5848484848484848\n"
     ]
    }
   ],
   "source": [
    "# Define parameter grid\n",
    "n_estimators_values = [100, 200, 300]\n",
    "max_depth_values = [8, 10, 12]\n",
    "\n",
    "best_f1 = 0\n",
    "best_params = None\n",
    "\n",
    "# Loop through all combinations of parameters\n",
    "for n_estimators in n_estimators_values:\n",
    "    for max_depth in max_depth_values:\n",
    "        # Train Random Forest model with current parameters\n",
    "        rf_model = RandomForestClassifier(\n",
    "            n_estimators=n_estimators, max_depth=max_depth, random_state=12345\n",
    "        )\n",
    "        rf_model.fit(features_train, target_train)\n",
    "        \n",
    "        # Make predictions on validation set\n",
    "        rf_predictions = rf_model.predict(features_valid)\n",
    "        \n",
    "        # Calculate F1 Score\n",
    "        rf_f1 = f1_score(target_valid, rf_predictions)\n",
    "        \n",
    "        # Track best F1 Score and corresponding parameters\n",
    "        if rf_f1 > best_f1:\n",
    "            best_f1 = rf_f1\n",
    "            best_params = (n_estimators, max_depth)\n",
    "\n",
    "# Output the best parameters and F1 Score\n",
    "print(\"Best Parameters: n_estimators =\", best_params[0], \", max_depth =\", best_params[1])\n",
    "print(\"Best F1 Score:\", best_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cf4624-3b67-44ad-bc5a-830b6c63d0d9",
   "metadata": {},
   "source": [
    "## Fine-Tuning Random Forest Model\n",
    "\n",
    "### Findings:\n",
    "- Grid search was performed with the following parameter ranges:\n",
    "  - `n_estimators`: [100, 200, 300]\n",
    "  - `max_depth`: [8, 10, 12]\n",
    "- The best parameter combination was:\n",
    "  - **`n_estimators = 300`**\n",
    "  - **`max_depth = 12`**\n",
    "- Performance metrics on the validation set:\n",
    "  - **Best F1 Score**: 0.5848\n",
    "\n",
    "### Observations:\n",
    "- The fine-tuned model achieved a significant improvement in F1 score compared to earlier attempts.\n",
    "- While the F1 score is very close to the target (0.59), further adjustments or additional techniques may push it over the threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4e649bae-6572-4592-96d0-8379bbef00fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Model Performance on Test Set:\n",
      "F1 Score: 0.5238828967642527\n",
      "AUC-ROC: 0.8564485639459667\n"
     ]
    }
   ],
   "source": [
    "# Train the best model on the training set\n",
    "final_model = RandomForestClassifier(n_estimators=300, max_depth=12, random_state=12345)\n",
    "final_model.fit(features_train, target_train)\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_predictions = final_model.predict(features_test)\n",
    "\n",
    "# Calculate F1 Score\n",
    "test_f1 = f1_score(target_test, test_predictions)\n",
    "\n",
    "# Calculate AUC-ROC\n",
    "test_probabilities = final_model.predict_proba(features_test)[:, 1]\n",
    "test_auc_roc = roc_auc_score(target_test, test_probabilities)\n",
    "\n",
    "print(\"Final Model Performance on Test Set:\")\n",
    "print(\"F1 Score:\", test_f1)\n",
    "print(\"AUC-ROC:\", test_auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085cd7f6-40ee-4897-8f2c-bf42398ae6c1",
   "metadata": {},
   "source": [
    "## Final Model Performance on Test Set\n",
    "\n",
    "### Findings:\n",
    "- The Random Forest model was trained with the best parameters:\n",
    "  - **`n_estimators = 300`**\n",
    "  - **`max_depth = 12`**\n",
    "- Performance metrics on the test set:\n",
    "  - **F1 Score**: 0.5239\n",
    "  - **AUC-ROC**: 0.8564\n",
    "\n",
    "### Observations:\n",
    "- The F1 score on the test set is lower than the validation set score (0.5848 → 0.5239).\n",
    "- AUC-ROC indicates that the model is still effective at distinguishing between classes.\n",
    "- The F1 score falling below the target suggests that additional techniques, such as further fine-tuning, ensemble method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5232825e-79ad-4033-a614-28d7d9b7dbdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Model Performance on Test Set:\n",
      "F1 Score: 0.5681492109038737\n",
      "AUC-ROC: 0.8509004288898782\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "# Train Gradient Boosting model\n",
    "gb_model = GradientBoostingClassifier(n_estimators=300, max_depth=5, random_state=12345)\n",
    "gb_model.fit(features_train, target_train)\n",
    "\n",
    "# Make predictions on test set\n",
    "test_predictions_gb = gb_model.predict(features_test)\n",
    "\n",
    "# Calculate F1 Score\n",
    "test_f1_gb = f1_score(target_test, test_predictions_gb)\n",
    "\n",
    "# Calculate AUC-ROC\n",
    "test_probabilities_gb = gb_model.predict_proba(features_test)[:, 1]\n",
    "test_auc_roc_gb = roc_auc_score(target_test, test_probabilities_gb)\n",
    "\n",
    "print(\"Gradient Boosting Model Performance on Test Set:\")\n",
    "print(\"F1 Score:\", test_f1_gb)\n",
    "print(\"AUC-ROC:\", test_auc_roc_gb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e0e266-ceec-4a42-9b3d-747aa2c85ceb",
   "metadata": {},
   "source": [
    "## Gradient Boosting Model Performance on Test Set\n",
    "\n",
    "### Findings:\n",
    "- A Gradient Boosting model was trained with the following parameters:\n",
    "  - **`n_estimators = 300`**\n",
    "  - **`max_depth = 5`**\n",
    "  - **`random_state = 12345`**\n",
    "- Performance metrics on the test set:\n",
    "  - **F1 Score**: 0.5681\n",
    "  - **AUC-ROC**: 0.8509\n",
    "\n",
    "### Observations:\n",
    "- The F1 score improved compared to the baseline models and is close to the project target of **≥ 0.59**.\n",
    "- The AUC-ROC score remains consistently high, indicating effective classification.\n",
    "- Further improvements may still be needed to achieve the target F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1a493569-03cd-4808-8fbf-1fc8c327c1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Random Forest Parameters: (500, 16, 5, 1)\n",
      "Best F1 Score on Validation Set: 0.5891238670694864\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "# Experiment with Random Forest parameters\n",
    "best_f1_rf = 0\n",
    "best_params_rf = None\n",
    "\n",
    "# Parameter grid\n",
    "for n_estimators in [300, 500]:\n",
    "    for max_depth in [12, 16]:\n",
    "        for min_samples_split in [2, 5]:\n",
    "            for min_samples_leaf in [1, 2]:\n",
    "                # Train the Random Forest model\n",
    "                rf_model = RandomForestClassifier(\n",
    "                    n_estimators=n_estimators,\n",
    "                    max_depth=max_depth,\n",
    "                    min_samples_split=min_samples_split,\n",
    "                    min_samples_leaf=min_samples_leaf,\n",
    "                    random_state=12345,\n",
    "                )\n",
    "                rf_model.fit(features_train, target_train)\n",
    "\n",
    "                # Evaluate on the validation set\n",
    "                rf_predictions = rf_model.predict(features_valid)\n",
    "                rf_f1 = f1_score(target_valid, rf_predictions)\n",
    "\n",
    "                # Track the best model\n",
    "                if rf_f1 > best_f1_rf:\n",
    "                    best_f1_rf = rf_f1\n",
    "                    best_params_rf = (n_estimators, max_depth, min_samples_split, min_samples_leaf)\n",
    "\n",
    "# Print the best parameters and F1 score\n",
    "print(\"Best Random Forest Parameters:\", best_params_rf)\n",
    "print(\"Best F1 Score on Validation Set:\", best_f1_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09fbf106-683d-45d0-b891-e81af1b38202",
   "metadata": {},
   "source": [
    "## Fine-Tuning Random Forest Model\n",
    "\n",
    "### Findings:\n",
    "- The Random Forest model was fine-tuned using a grid search with the following parameter ranges:\n",
    "  - `n_estimators`: [300, 500]\n",
    "  - `max_depth`: [12, 16]\n",
    "  - `min_samples_split`: [2, 5]\n",
    "  - `min_samples_leaf`: [1, 2]\n",
    "- The best parameter combination was:\n",
    "  - **`n_estimators = 500`**\n",
    "  - **`max_depth = 16`**\n",
    "  - **`min_samples_split = 5`**\n",
    "  - **`min_samples_leaf = 1`**\n",
    "- Performance metrics on the validation set:\n",
    "  - **Best F1 Score**: 0.5891\n",
    "\n",
    "### Observations:\n",
    "- The fine-tuned model achieved an F1 score very close to the target. Further evaluation on the test set is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0e6ad465-ab1d-4a1f-8d94-66cabae550a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Random Forest Model Performance on Test Set:\n",
      "F1 Score: 0.5393939393939394\n",
      "AUC-ROC: 0.8563496239530725\n"
     ]
    }
   ],
   "source": [
    "# Train the final model with best parameters\n",
    "final_rf_model = RandomForestClassifier(\n",
    "    n_estimators=500, max_depth=16, min_samples_split=5, min_samples_leaf=1, random_state=12345\n",
    ")\n",
    "final_rf_model.fit(features_train, target_train)\n",
    "\n",
    "# Evaluate on the test set\n",
    "final_test_predictions = final_rf_model.predict(features_test)\n",
    "\n",
    "# Calculate F1 Score\n",
    "final_test_f1 = f1_score(target_test, final_test_predictions)\n",
    "\n",
    "# Calculate AUC-ROC\n",
    "final_test_probabilities = final_rf_model.predict_proba(features_test)[:, 1]\n",
    "final_test_auc_roc = roc_auc_score(target_test, final_test_probabilities)\n",
    "\n",
    "print(\"Final Random Forest Model Performance on Test Set:\")\n",
    "print(\"F1 Score:\", final_test_f1)\n",
    "print(\"AUC-ROC:\", final_test_auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c18cdf-7f5b-4506-8b8b-ff9bdb44cf87",
   "metadata": {},
   "source": [
    "## Final Random Forest Model Performance on Test Set\n",
    "\n",
    "### Findings:\n",
    "- The Random Forest model was trained with the best parameters:\n",
    "  - **`n_estimators = 500`**\n",
    "  - **`max_depth = 16`**\n",
    "  - **`min_samples_split = 5`**\n",
    "  - **`min_samples_leaf = 1`**\n",
    "- Performance metrics on the test set:\n",
    "  - **F1 Score**: 0.5394\n",
    "  - **AUC-ROC**: 0.8563\n",
    "\n",
    "### Observations:\n",
    "- The F1 score on the test set fell short of the target **≥ 0.59**.\n",
    "- The AUC-ROC remains consistently strong, showing the model's ability to distinguish between classes.\n",
    "- Despite fine-tuning, the model requires further improvements to meet the project requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "68362b3d-a655-4204-83c4-258e79e6f94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Model Performance on Test Set:\n",
      "F1 Score: 0.5921052631578947\n",
      "AUC-ROC: 0.837814865284205\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "# Calculate scale_pos_weight for class imbalance\n",
    "scale_pos_weight = target_train.value_counts()[0] / target_train.value_counts()[1]\n",
    "\n",
    "# Train XGBoost model with initial parameters\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.1,\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    random_state=12345\n",
    ")\n",
    "xgb_model.fit(features_train, target_train)\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_predictions_xgb = xgb_model.predict(features_test)\n",
    "\n",
    "# Calculate F1 Score\n",
    "test_f1_xgb = f1_score(target_test, test_predictions_xgb)\n",
    "\n",
    "# Calculate AUC-ROC\n",
    "test_probabilities_xgb = xgb_model.predict_proba(features_test)[:, 1]\n",
    "test_auc_roc_xgb = roc_auc_score(target_test, test_probabilities_xgb)\n",
    "\n",
    "print(\"XGBoost Model Performance on Test Set:\")\n",
    "print(\"F1 Score:\", test_f1_xgb)\n",
    "print(\"AUC-ROC:\", test_auc_roc_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c686937-ac0b-415f-ab9b-a6364ee401ff",
   "metadata": {},
   "source": [
    "## XGBoost Model Performance on Test Set\n",
    "\n",
    "### Findings:\n",
    "- The XGBoost model was trained with the following parameters:\n",
    "  - **`n_estimators = 300`**\n",
    "  - **`max_depth = 5`**\n",
    "  - **`learning_rate = 0.1`**\n",
    "  - **`scale_pos_weight`**: Adjusted for class imbalance.\n",
    "- Performance metrics on the test set:\n",
    "  - **F1 Score**: 0.5921\n",
    "  - **AUC-ROC**: 0.8378\n",
    "\n",
    "### Observations:\n",
    "- The F1 score successfully surpassed the project target of **≥ 0.59**, demonstrating the effectiveness of XGBoost with fine-tuned parameters.\n",
    "- The AUC-ROC value indicates strong overall classification performance, making XGBoost the best model in this project.\n",
    "\n",
    "\n",
    "----\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970aa8a9-1fc5-4490-b362-20fe399a455b",
   "metadata": {},
   "source": [
    "# Project Summary: Predicting Customer Churn for Beta Bank\n",
    "\n",
    "## Project Overview\n",
    "Beta Bank sought to predict customer churn to proactively retain valuable clients. The project aimed to build a classification model with an F1 score of at least **0.59**. \n",
    "\n",
    "## Key Steps and Findings\n",
    "\n",
    "### 1. Data Preparation\n",
    "- **Data Cleaning**:\n",
    "  - Missing values in the `Tenure` column were filled with the median value.\n",
    "  - Irrelevant columns (`RowNumber`, `CustomerId`, `Surname`) were dropped.\n",
    "- **Feature Encoding**:\n",
    "  - Categorical variables were encoded using One-Hot Encoding (`Geography`) and binary conversion (`Gender`).\n",
    "- **Dataset Splitting**:\n",
    "  - Data was split into training (60%), validation (20%), and test (20%) sets.\n",
    "\n",
    "### 2. Class Imbalance Investigation\n",
    "- **Findings**:\n",
    "  - Class imbalance was observed with ~80% of customers staying (`Exited = 0`) and ~20% leaving (`Exited = 1`).\n",
    "\n",
    "### 3. Baseline Modeling\n",
    "- Logistic Regression without handling imbalance achieved:\n",
    "  - **F1 Score**: 0.0839\n",
    "  - **AUC-ROC**: 0.6728\n",
    "\n",
    "### 4. Addressing Class Imbalance\n",
    "- **Class Weighting**: Improved F1 to **0.4921**.\n",
    "- **Upsampling**: Improved F1 to **0.4512**.\n",
    "\n",
    "### 5. Model Selection and Fine-Tuning\n",
    "- **Random Forest**: Achieved an F1 score of **0.5394** on the test set after fine-tuning.\n",
    "- **XGBoost**: Outperformed all models with:\n",
    "  - **F1 Score**: 0.5921\n",
    "  - **AUC-ROC**: 0.8378\n",
    "\n",
    "## Final Results\n",
    "- The XGBoost model successfully met the project target with an F1 score of **0.5921** on the test set.\n",
    "\n",
    "## Conclusion\n",
    "- The project successfully developed a model capable of predicting customer churn with strong performance.\n",
    "- The XGBoost model demonstrated the highest F1 score and remains the recommended solution for deployment."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
